# Recommended AI Models for Code Development

**Version:** 1.1.2
**Last Updated:** 2025-11-14
**Pricing Last Verified:** 2025-11-14
**Purpose:** Curated OpenRouter model recommendations for code development tasks
**Maintained By:** MadAppGang Claude Code Team

---

## Quick Reference - Model IDs Only

**Coding (Fast):**
- `x-ai/grok-code-fast-1` - Ultra-fast coding, $0.85/1M, 256K ‚≠ê
- `google/gemini-2.5-flash` - Massive context, $0.19/1M, 1M ‚≠ê
- `deepseek/deepseek-v3-0324` - Affordable coding, $0.21/1M, 64K

**Reasoning (Architecture):**
- `openai/gpt-5.1-codex` - Specialized software engineering, $5.63/1M, 400K ‚≠ê
- `z-ai/glm-4.6` - Best for planning, $0.75/1M, 128K ‚≠ê

**Vision (UI Analysis):**
- `qwen/qwen3-vl-235b` - Premium vision, $5.00/1M, 32K ‚≠ê

**Budget (Free/Cheap):**
- `minimax/minimax-m2` - FREE, 128K ‚≠ê
- `google/gemini-2.5-flash` - Ultra-cheap massive context, $0.19/1M, 1M

---

## How to Use This Guide

### For AI Agents

This file provides curated model recommendations for different code development tasks. When a user needs to select an AI model for plan review, code review, or other multi-model workflows:

1. **Start with Quick Reference** - Extract model slugs from the top section (6-9 recommended models)
2. **Read detailed sections** for context on "Best For", "Trade-offs", and use cases
3. **Use ‚≠ê markers** to identify top recommendations in each category
4. **Present options to user** with pricing, context window, and use case guidance
5. **Copy OpenRouter IDs exactly** as shown in backticks (e.g., `x-ai/grok-code-fast-1`)

### For Human Users

Browse categories to find models that match your needs:
- **Fast Coding Models** ‚ö° - Quick iterations, code generation, reviews
- **Advanced Reasoning Models** üß† - Architecture, complex problem-solving
- **Vision & Multimodal Models** üëÅÔ∏è - UI analysis, screenshot reviews
- **Budget-Friendly Models** üí∞ - High-volume tasks, simple operations

Each model includes:
- OpenRouter ID (for use with Claudish CLI)
- Context window and pricing information
- Best use cases and trade-offs
- Guidance on when to use or avoid

---

## Quick Reference Table

| Model | Category | Speed | Quality | Cost | Context | Recommended For |
|-------|----------|-------|---------|------|---------|----------------|
| x-ai/grok-code-fast-1 | Coding ‚ö° | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | üí∞ | 256K | Ultra-fast coding, budget-friendly |
| google/gemini-2.5-flash | Coding ‚ö° | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | üí∞ | 1049K | Fast coding, huge context |
| deepseek/deepseek-v3-0324 | Coding ‚ö° | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | üí∞ | 64K | Fast affordable coding |
| openai/gpt-5.1-codex | Reasoning üß† | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | üí∞üí∞üí∞üí∞ | 400K | Specialized software engineering |
| z-ai/glm-4.6 | Reasoning üß† | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | üí∞üí∞ | 128K | Architecture planning |
| qwen/qwen3-vl-235b | Vision üëÅÔ∏è | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | üí∞üí∞üí∞ | 32K | Vision-language tasks |
| minimax/minimax-m2 | Budget üí∞ | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Free | 128K | Free coding tasks |

**Legend:**
- Speed: ‚ö° (1-5, more = faster)
- Quality: ‚≠ê (1-5, more = better)
- Cost: üí∞ (1-5, more = expensive)
- Context: Token window size

---

## Category 1: Fast Coding Models ‚ö°

**Use When:** You need quick code generation, reviews, or iterations. Speed is priority.

### x-ai/grok-code-fast-1 (‚≠ê RECOMMENDED)

- **Provider:** xAI
- **OpenRouter ID:** `x-ai/grok-code-fast-1`
- **Model Version:** Grok Code Fast 1 (2025-11-14)
- **Context Window:** 256,000 tokens
- **Pricing:** $0.20/1M input, $1.50/1M output (Verified: 2025-11-14)
- **Response Time:** Ultra-fast (<2s typical)

**Best For:**
- Ultra-fast code reviews
- Quick syntax and logic checks
- Rapid prototyping
- Agentic coding workflows
- Visible reasoning traces
- Budget-conscious fast development

**Trade-offs:**
- Less sophisticated than premium models for complex architecture
- Smaller context than Gemini (256K vs 1049K)
- May miss subtle edge cases in complex systems

**When to Use:**
- ‚úÖ **Budget-conscious fast coding** ($0.85/1M avg!)
- ‚úÖ Inner dev loop (test-fix-test cycles)
- ‚úÖ Quick feedback on code changes
- ‚úÖ Large codebases needing fast turnaround
- ‚úÖ Reasoning traces for debugging
- ‚úÖ High-volume code reviews

**Avoid For:**
- ‚ùå Complex architectural decisions (use advanced reasoning models)
- ‚ùå Security-critical code review (use premium models)
- ‚ùå Performance optimization requiring deep analysis
- ‚ùå Tasks requiring >256K context

---

### google/gemini-2.5-flash (‚≠ê RECOMMENDED)

- **Provider:** Google
- **OpenRouter ID:** `google/gemini-2.5-flash`
- **Model Version:** Gemini 2.5 Flash (2025-11-14)
- **Context Window:** 1,049,000 tokens
- **Pricing:** $0.075/1M input, $0.30/1M output (Verified: 2025-11-14)
- **Response Time:** Very fast (<2s typical)

**Best For:**
- **Ultra-cheap massive context** (1M+ tokens!)
- Fast code generation across entire codebases
- Multi-file refactoring
- Large repository analysis
- Quick comprehension of complex systems
- High-volume simple coding tasks

**Trade-offs:**
- Lower quality than Gemini Pro for complex reasoning
- Less specialized than coding-focused models
- Better for breadth than depth

**When to Use:**
- ‚úÖ **Massive context at ultra-low cost** (1M tokens at $0.19/1M avg!)
- ‚úÖ Whole codebase analysis
- ‚úÖ Multi-file architectural planning
- ‚úÖ Large-scale refactoring
- ‚úÖ High-volume tasks (thousands of reviews)
- ‚úÖ Quick iterations on large projects

**Avoid For:**
- ‚ùå Critical code paths requiring highest quality
- ‚ùå Complex architectural decisions (use reasoning models)
- ‚ùå Security-critical reviews
- ‚ùå Production releases requiring maximum accuracy

---

### deepseek/deepseek-v3-0324

- **Provider:** DeepSeek
- **OpenRouter ID:** `deepseek/deepseek-v3-0324`
- **Model Version:** DeepSeek V3 (2025-03-24)
- **Context Window:** 64,000 tokens
- **Pricing:** $0.14/1M input, $0.28/1M output (Verified: 2025-11-14)
- **Response Time:** Fast (~3s typical)

**Best For:**
- Fast affordable code generation
- Algorithm implementation
- Mathematical problem-solving
- Code optimization
- Programming challenges
- Budget-friendly quick iterations

**Trade-offs:**
- Smaller context (64K)
- Less sophisticated for complex systems
- May require more guidance for edge cases

**When to Use:**
- ‚úÖ **Ultra-affordable fast coding** ($0.21/1M avg!)
- ‚úÖ Algorithm development
- ‚úÖ Math and programming tasks
- ‚úÖ Quick prototyping
- ‚úÖ High-volume simple tasks
- ‚úÖ Learning and experimentation

**Avoid For:**
- ‚ùå Large files or projects (64K limit)
- ‚ùå Complex architectural planning
- ‚ùå Multi-file system design
- ‚ùå Production-critical implementations

---

## Category 2: Advanced Reasoning Models üß†

**Use When:** You need deep analysis, architectural planning, or complex problem-solving.

### openai/gpt-5.1-codex (‚≠ê RECOMMENDED)

- **Provider:** OpenAI
- **OpenRouter ID:** `openai/gpt-5.1-codex`
- **Model Version:** GPT-5.1-Codex (2025-11-13)
- **Context Window:** 400,000 tokens
- **Pricing:** $1.25/1M input, $10.00/1M output (Verified: 2025-11-14)
- **Response Time:** Fast with adjustable reasoning (~3-5s typical)

**Best For:**
- **Specialized software engineering and agentic coding workflows**
- Large-scale refactoring across multiple files
- Structured code review with dependency analysis
- Building projects from scratch
- Feature development with extended reasoning
- Debugging complex systems
- UI development with multimodal screenshot support
- Long-running multi-hour engineering tasks

**Trade-offs:**
- Premium pricing ($5.63/1M avg)
- More expensive than budget reasoning models
- May be overkill for simple CRUD operations

**When to Use:**
- ‚úÖ **Complex engineering tasks** requiring deep reasoning
- ‚úÖ **Agentic coding workflows** (multi-step autonomous execution)
- ‚úÖ **Large-scale refactoring** across codebases
- ‚úÖ **Code review with dependency analysis** (validates against tests)
- ‚úÖ **UI development** with screenshot/image analysis (multimodal)
- ‚úÖ **Multi-hour project execution** (adjustable reasoning effort)
- ‚úÖ **Critical code paths** requiring highest quality
- ‚úÖ Projects where quality > cost

**Avoid For:**
- ‚ùå Simple CRUD operations or basic features
- ‚ùå Quick syntax fixes or trivial changes
- ‚ùå Ultra-budget projects (<$1/1M requirement)
- ‚ùå When Gemini Flash or budget models suffice

---

### z-ai/glm-4.6 (‚≠ê RECOMMENDED)

- **Provider:** Zhipu AI
- **OpenRouter ID:** `z-ai/glm-4.6`
- **Model Version:** GLM-4.6 (2025-11-14)
- **Context Window:** 128,000 tokens
- **Pricing:** $0.50/1M input, $1.00/1M output (Verified: 2025-11-14)
- **Response Time:** Moderate (~5s typical)

**Best For:**
- **Architectural planning and design**
- Complex system design decisions
- Multi-component integration planning
- Code review with reasoning
- Large-scale refactoring plans
- Advanced problem-solving

**Trade-offs:**
- Moderate pricing ($0.75/1M avg)
- Smaller context than premium models (128K)
- Slower than fast coding models

**When to Use:**
- ‚úÖ **Architecture planning** (PHASE 1 in /implement)
- ‚úÖ **Plan reviews** (PHASE 1.5 multi-model review)
- ‚úÖ Complex integration scenarios
- ‚úÖ System design decisions
- ‚úÖ Mid-range budget projects
- ‚úÖ Projects requiring reasoning quality

**Avoid For:**
- ‚ùå Simple CRUD operations
- ‚ùå Quick syntax fixes
- ‚ùå Ultra-large context needs (>128K)
- ‚ùå When ultra-fast response is critical

---

## Category 3: Vision & Multimodal Models üëÅÔ∏è

**Use When:** You need UI/UX analysis, screenshot reviews, or diagram interpretation.

### qwen/qwen3-vl-235b (‚≠ê RECOMMENDED)

- **Provider:** Qwen (Alibaba Cloud)
- **OpenRouter ID:** `qwen/qwen3-vl-235b`
- **Model Version:** Qwen3 VL 235B (2025-11-14)
- **Context Window:** 32,000 tokens
- **Pricing:** $3.00/1M input, $7.00/1M output (Verified: 2025-11-14)
- **Vision:** Vision-language model
- **Response Time:** Moderate (~5s typical)

**Best For:**
- **Premium vision-language tasks**
- UI/UX design analysis
- Screenshot-based debugging
- Design fidelity validation
- Component recognition
- Visual accessibility audits

**Trade-offs:**
- Premium pricing for vision ($5.00/1M avg)
- Smaller context than text models (32K)
- Slower than fast coding models

**When to Use:**
- ‚úÖ **Design fidelity validation** (PHASE 2.5 in /implement)
- ‚úÖ Screenshot-based UI reviews
- ‚úÖ Figma design to code comparison
- ‚úÖ Accessibility visual audits
- ‚úÖ Design system consistency checks
- ‚úÖ High-quality vision analysis

**Avoid For:**
- ‚ùå Pure code review (use coding models)
- ‚ùå Simple layout checks (use budget vision)
- ‚ùå Ultra-large design systems (>32K context)
- ‚ùå Budget-critical projects

---

## Category 4: Budget-Friendly Models üí∞

**Use When:** You need to minimize costs for high-volume or simple tasks.

### minimax/minimax-m2 (‚≠ê RECOMMENDED)

- **Provider:** MiniMax
- **OpenRouter ID:** `minimax/minimax-m2`
- **Model Version:** MiniMax M2 (2025-11-14)
- **Context Window:** 128,000 tokens
- **Pricing:** **FREE** (Verified: 2025-11-14)
- **Response Time:** Fast (~3s typical)

**Best For:**
- **Free coding tasks**
- Learning and experimentation
- High-volume simple operations
- Quick prototyping
- Code comprehension
- Educational projects

**Trade-offs:**
- Rate limits on free tier
- May have availability issues during peak times
- No SLA guarantees
- Quality may vary with load

**When to Use:**
- ‚úÖ **Zero budget** (completely free!)
- ‚úÖ Learning and experimentation
- ‚úÖ High-volume simple tasks
- ‚úÖ Quick iterations
- ‚úÖ Personal projects
- ‚úÖ 128K context needs

**Avoid For:**
- ‚ùå Production-critical tasks (no SLA)
- ‚ùå Time-sensitive workflows (potential rate limits)
- ‚ùå When reliability is critical
- ‚ùå Complex architectural decisions

---

## Model Selection Decision Tree

Use this flowchart to choose the right model:

```
START: What is your primary need?

‚îå‚îÄ Architecture Planning or Complex Reasoning?
‚îÇ  ‚îú‚îÄ Budget < $1/1M ‚Üí deepseek/deepseek-v3-0324 ($0.21/1M)
‚îÇ  ‚îú‚îÄ Need massive context (>400K) ‚Üí google/gemini-2.5-flash ($0.19/1M, 1M context)
‚îÇ  ‚îú‚îÄ Premium quality + agentic workflows ‚Üí openai/gpt-5.1-codex ‚≠ê ($5.63/1M, 400K)
‚îÇ  ‚îî‚îÄ Best value ‚Üí z-ai/glm-4.6 ‚≠ê ($0.75/1M, 128K context)

‚îå‚îÄ Fast Code Review or Generation?
‚îÇ  ‚îú‚îÄ Budget < $0.25/1M ‚Üí google/gemini-2.5-flash ($0.19/1M)
‚îÇ  ‚îú‚îÄ Need huge context (>256K) ‚Üí google/gemini-2.5-flash ($0.19/1M, 1M)
‚îÇ  ‚îî‚îÄ Recommended ‚Üí x-ai/grok-code-fast-1 ‚≠ê ($0.85/1M, ultra-fast)

‚îå‚îÄ UI/Design Analysis (Screenshots)?
‚îÇ  ‚îî‚îÄ Recommended ‚Üí qwen/qwen3-vl-235b ‚≠ê ($5.00/1M, 32K)

‚îå‚îÄ Budget is Top Priority?
‚îÇ  ‚îú‚îÄ Completely free ‚Üí minimax/minimax-m2 (FREE, 128K context)
‚îÇ  ‚îú‚îÄ Ultra-cheap + massive context ‚Üí google/gemini-2.5-flash ($0.19/1M, 1M)
‚îÇ  ‚îî‚îÄ Recommended ‚Üí minimax/minimax-m2 ‚≠ê (FREE!)

‚îå‚îÄ High-Volume Simple Tasks?
‚îÇ  ‚îú‚îÄ Free tier ‚Üí minimax/minimax-m2 (FREE)
‚îÇ  ‚îî‚îÄ Recommended ‚Üí google/gemini-2.5-flash ‚≠ê ($0.19/1M, 1M context)

‚îî‚îÄ Not sure? ‚Üí Start with x-ai/grok-code-fast-1 (fast + affordable)
```

---

## Performance Benchmarks

### Speed Comparison (Typical Response Times)

| Model | Simple Task | Complex Task | Large Context |
|-------|-------------|--------------|---------------|
| google/gemini-2.5-flash | <2s | 3-4s | 5s |
| x-ai/grok-code-fast-1 | <2s | 4-5s | 6s |
| minimax/minimax-m2 | 3s | 5-6s | 7s |
| deepseek/deepseek-v3-0324 | 3s | 5-6s | 7s |
| openai/gpt-5.1-codex | 3-5s | 6-8s | 10s |
| z-ai/glm-4.6 | 4-5s | 8-10s | 12s |
| qwen/qwen3-vl-235b | 4-5s | 8-10s | N/A (32K max) |

**Notes:**
- Times are approximate and vary based on load
- "Large Context" = >100K tokens
- Reasoning models may be slower for chain-of-thought
- Vision models (qwen3-vl-235b) have smaller context limits

### Cost Comparison (Per 1M Tokens)

| Model | Input | Output | Total (1:1 ratio) |
|-------|-------|--------|-------------------|
| minimax/minimax-m2 | FREE | FREE | FREE |
| google/gemini-2.5-flash | $0.075 | $0.30 | $0.19 |
| deepseek/deepseek-v3-0324 | $0.14 | $0.28 | $0.21 |
| z-ai/glm-4.6 | $0.50 | $1.00 | $0.75 |
| x-ai/grok-code-fast-1 | $0.20 | $1.50 | $0.85 |
| qwen/qwen3-vl-235b | $3.00 | $7.00 | $5.00 |
| openai/gpt-5.1-codex | $1.25 | $10.00 | $5.63 |

**Notes:**
- Prices from OpenRouter (subject to change)
- "Total" assumes equal input/output tokens
- Typical code review is ~70% input, 30% output

### Quality vs Cost Analysis

**Best Value for Code Review:**
1. **minimax/minimax-m2** - FREE with 128K context (unbeatable value!)
2. **google/gemini-2.5-flash** - Massive context at ultra-low cost ($0.19/1M)
3. **x-ai/grok-code-fast-1** - Great quality + speed at $0.85/1M

**Best Quality (Cost No Object):**
1. **qwen/qwen3-vl-235b** - Premium vision-language ($5.00/1M)
2. **z-ai/glm-4.6** - Advanced reasoning ($0.75/1M)
3. **x-ai/grok-code-fast-1** - Strong coding quality ($0.85/1M)

**Best for Massive Context:**
1. **google/gemini-2.5-flash** - 1M tokens at $0.19/1M (!)
2. **x-ai/grok-code-fast-1** - 256K tokens at $0.85/1M
3. **minimax/minimax-m2** - 128K tokens FREE

---

## Integration Examples

### Example 1: Multi-Model Plan Review (PHASE 1.5)

**In /implement command:**

```markdown
## PHASE 1.5: Multi-Model Plan Review

**Step 1:** Read model recommendations

Use Read tool to load: ${CLAUDE_PLUGIN_ROOT}/recommended-models.md

**Step 2:** Extract recommended reasoning models

From section "Advanced Reasoning Models üß†", extract models marked with ‚≠ê:
- z-ai/glm-4.6 (primary recommendation - $0.75/1M)
- Alternative: x-ai/grok-code-fast-1 (fast + affordable - $0.85/1M)

**Step 3:** Present options to user

AskUserQuestion with these options:

"Select AI models for architecture plan review:

**Recommended (Advanced Reasoning):**
‚Ä¢ z-ai/glm-4.6 - Best for architectural decisions ($0.75/1M)

**Fast & Affordable:**
‚Ä¢ x-ai/grok-code-fast-1 - Quick architectural feedback ($0.85/1M)
‚Ä¢ google/gemini-2.5-flash - Massive context analysis ($0.19/1M)

**Custom:**
‚Ä¢ Enter any OpenRouter model ID

**Skip:**
‚Ä¢ Continue without multi-model review

Which models would you like to use? (select 1-3 or skip)"
```

### Example 2: Budget-Optimized Code Review

**In code review workflow:**

```markdown
## Budget-Optimized Multi-Model Review

**Read recommendations:**
${CLAUDE_PLUGIN_ROOT}/recommended-models.md ‚Üí "Budget-Friendly Models"

**Extract budget models:**
- minimax/minimax-m2 (FREE) - Zero cost!
- google/gemini-2.5-flash ($0.19/1M) - Ultra-cheap
- deepseek/deepseek-v3-0324 ($0.21/1M) - Affordable reasoning

**Run 3 parallel reviews:**
1. Claude Sonnet (internal, comprehensive)
2. MiniMax M2 (external, FREE!)
3. Gemini Flash (external, ultra-cheap)

**Total cost for 100K token review:**
- Claude Sonnet: ~$1.80
- MiniMax M2: FREE (!)
- Gemini Flash: ~$0.019
- **Grand Total: ~$1.82** (vs $9.00 for 3x Sonnet)
```

### Example 3: Vision Task Model Selection

**In UI validation workflow:**

```markdown
## UI Design Validation

**Read recommendations:**
${CLAUDE_PLUGIN_ROOT}/recommended-models.md ‚Üí "Vision & Multimodal Models"

**Task:** Compare Figma design screenshot to implemented UI

**Recommended model:**
qwen/qwen3-vl-235b
- Vision-language model (235B parameters)
- 32K token context
- Premium vision quality ($5.00/1M)
- Strong UI analysis capabilities

**Run with Claudish:**
npx claudish --model qwen/qwen3-vl-235b --stdin --quiet < prompt.txt
```

---

## Maintenance and Updates

### How to Update This File

**Step 1: Edit Source**
```bash
# Edit the source file (ONLY place to edit!)
vim shared/recommended-models.md
```

**Step 2: Sync to Plugins**
```bash
# Distribute updates to all plugins
bun run sync-shared
```

**Step 3: Verify**
```bash
# Check files were updated
cat plugins/frontend/recommended-models.md | head -20
cat plugins/bun/recommended-models.md | head -20
cat plugins/code-analysis/recommended-models.md | head -20
```

### Update Checklist

When adding a new model:
- [ ] Add to appropriate category section
- [ ] Include all required fields (Provider, ID, Context, Pricing, etc.)
- [ ] Write "Best For", "Trade-offs", "When to Use", "Avoid For"
- [ ] Update Quick Reference Table
- [ ] Update Decision Tree if needed
- [ ] Update Performance Benchmarks
- [ ] Run sync script
- [ ] Test in a command (verify AI can extract the model)

When removing a model:
- [ ] Remove from category section
- [ ] Remove from Quick Reference Table
- [ ] Update Decision Tree if needed
- [ ] Update Performance Benchmarks
- [ ] Run sync script
- [ ] Update any commands that hardcoded the model

When updating pricing:
- [ ] Update in model entry
- [ ] Update in Quick Reference Table
- [ ] Update in Cost Comparison table
- [ ] Update last-updated date at top
- [ ] Run sync script

---

## Questions and Support

**For model recommendations:**
- See category sections and decision tree above
- Ask in project discussions or issues

**For technical issues:**
- Check `shared/README.md` for sync pattern
- See `CLAUDE.md` for project overview
- Contact: Jack Rudenko (i@madappgang.com)

**To suggest new models:**
- Open an issue with model details
- Include: Provider, ID, pricing, use cases
- Maintainers will evaluate and add

---

**Maintained By:** MadAppGang Claude Code Team
**Repository:** https://github.com/MadAppGang/claude-code
**License:** MIT
